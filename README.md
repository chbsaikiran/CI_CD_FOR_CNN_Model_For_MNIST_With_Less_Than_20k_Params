## STEPS TO RUN THE CODE
1. pip install -r requirements.txt
2. python tests/test_model.py


## BELOW ARE THE RESULTS OF THE TRAINING

## Epoch 1:
loss=0.017595084384083748 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.63it/s]

Test set: Average loss: 0.0539, Accuracy: 9825/10000 (98%)

Learning Rate = 0.01

## Epoch 2:
loss=0.11072218418121338 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.29it/s]

Test set: Average loss: 0.0509, Accuracy: 9828/10000 (98%)

Learning Rate = 0.01

## Epoch 3:
loss=0.021019043400883675 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.77it/s]

Test set: Average loss: 0.0317, Accuracy: 9887/10000 (99%)

Learning Rate = 0.01

## Epoch 4:
loss=0.017021944746375084 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.49it/s]

Test set: Average loss: 0.0290, Accuracy: 9906/10000 (99%)

Learning Rate = 0.01

## Epoch 5:
loss=0.034775540232658386 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.40it/s]

Test set: Average loss: 0.0264, Accuracy: 9906/10000 (99%)

Learning Rate = 0.01

## Epoch 6:
loss=0.023437118157744408 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.06it/s]

Test set: Average loss: 0.0249, Accuracy: 9913/10000 (99%)

Learning Rate = 0.01

## Epoch 7:
loss=0.03141943737864494 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.66it/s]

Test set: Average loss: 0.0240, Accuracy: 9921/10000 (99%)

Learning Rate = 0.01

## Epoch 8:
loss=0.014088020659983158 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.63it/s]

Test set: Average loss: 0.0246, Accuracy: 9922/10000 (99%)

Learning Rate = 0.01

## Epoch 9:
loss=0.015576012432575226 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.91it/s]

Test set: Average loss: 0.0246, Accuracy: 9924/10000 (99%)

Learning Rate = 0.001

## Epoch 10:
loss=0.002952931448817253 batch_id=468: 100%|██████████| 469/469 [00:18<00:00, 25.10it/s]

Test set: Average loss: 0.0192, Accuracy: 9935/10000 (99%)

Learning Rate = 0.001

## Epoch 11:
loss=0.006960914935916662 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.01it/s]

Test set: Average loss: 0.0188, Accuracy: 9936/10000 (99%)

Learning Rate = 0.001

## Epoch 12:
loss=0.008423689752817154 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.81it/s]

Test set: Average loss: 0.0186, Accuracy: 9933/10000 (99%)

Learning Rate = 0.001

## Epoch 13:
loss=0.011705243028700352 batch_id=468: 100%|██████████| 469/469 [00:18<00:00, 24.90it/s]

Test set: Average loss: 0.0187, Accuracy: 9938/10000 (99%)

Learning Rate = 0.001

## Epoch 14:
loss=0.041759613901376724 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.43it/s]

Test set: Average loss: 0.0181, Accuracy: 9939/10000 (99%)

Learning Rate = 0.001

## Epoch 15:
loss=0.01909550651907921 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.72it/s]

Test set: Average loss: 0.0183, Accuracy: 9939/10000 (99%)

Learning Rate = 0.001

## Epoch 16:
loss=0.026368873193860054 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.29it/s]

Test set: Average loss: 0.0182, Accuracy: 9940/10000 (99%)

Learning Rate = 0.0001

## Epoch 17:
loss=0.008405785076320171 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.48it/s]

Test set: Average loss: 0.0182, Accuracy: 9942/10000 (99%)

Learning Rate = 0.0001

## Epoch 18:
loss=0.00746827432885766 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.94it/s]

Test set: Average loss: 0.0183, Accuracy: 9941/10000 (99%)

Learning Rate = 0.0001

## Epoch 19:
loss=0.06835322827100754 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.18it/s]

Test set: Average loss: 0.0183, Accuracy: 9941/10000 (99%)

Learning Rate = 0.0001