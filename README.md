## STEPS TO RUN THE CODE
1. pip install -r requirements.txt
2. python tests/test_model.py


## BELOW ARE THE RESULTS OF THE TRAINING

## Epoch 1:
loss=0.0005057222442701459 batch_id=539: 100%|██████████| 540/540 [00:23<00:00, 23.38it/s]

Test set: Average loss: 0.0433, Accuracy: 9871/10000 (99%)

Learning Rate = 0.01

## Epoch 2:
loss=0.2189137041568756 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 23.98it/s]

Test set: Average loss: 0.0327, Accuracy: 9899/10000 (99%)

Learning Rate = 0.01

## Epoch 3:
loss=0.06324779242277145 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 24.44it/s]

Test set: Average loss: 0.0328, Accuracy: 9892/10000 (99%)

Learning Rate = 0.01

## Epoch 4:
loss=0.002750706858932972 batch_id=539: 100%|██████████| 540/540 [00:21<00:00, 24.74it/s]

Test set: Average loss: 0.0276, Accuracy: 9912/10000 (99%)

Learning Rate = 0.01

## Epoch 5:
loss=0.00114596844650805 batch_id=539: 100%|██████████| 540/540 [00:21<00:00, 25.05it/s]

Test set: Average loss: 0.0260, Accuracy: 9917/10000 (99%)

Learning Rate = 0.01

## Epoch 6:
loss=0.01396060548722744 batch_id=539: 100%|██████████| 540/540 [00:21<00:00, 24.97it/s]

Test set: Average loss: 0.0278, Accuracy: 9918/10000 (99%)

Learning Rate = 0.01

## Epoch 7:
loss=0.000977952964603901 batch_id=539: 100%|██████████| 540/540 [00:21<00:00, 24.77it/s]

Test set: Average loss: 0.0233, Accuracy: 9923/10000 (99%)

Learning Rate = 0.01

## Epoch 8:
loss=0.0004093570460099727 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 24.28it/s]

Test set: Average loss: 0.0248, Accuracy: 9923/10000 (99%)

Learning Rate = 0.01

## Epoch 9:
loss=0.010113395750522614 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 24.32it/s]

Test set: Average loss: 0.0274, Accuracy: 9920/10000 (99%)

Learning Rate = 0.001

## Epoch 10:
loss=0.0009431780781596899 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 23.99it/s]

Test set: Average loss: 0.0208, Accuracy: 9934/10000 (99%)

Learning Rate = 0.001

## Epoch 11:
loss=0.008699139580130577 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 23.81it/s]

Test set: Average loss: 0.0203, Accuracy: 9930/10000 (99%)

Learning Rate = 0.001

## Epoch 12:
loss=9.4804578111507e-05 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 24.05it/s]

Test set: Average loss: 0.0198, Accuracy: 9937/10000 (99%)

Learning Rate = 0.001

## Epoch 13:
loss=0.0006034522084519267 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 24.06it/s]

Test set: Average loss: 0.0198, Accuracy: 9938/10000 (99%)

Learning Rate = 0.001

## Epoch 14:
loss=0.004314211197197437 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 23.77it/s]

Test set: Average loss: 0.0197, Accuracy: 9939/10000 (99%)

Learning Rate = 0.001

## Epoch 15:
loss=0.00018200902559328824 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 23.94it/s]

Test set: Average loss: 0.0196, Accuracy: 9941/10000 (99%)

Learning Rate = 0.001

## Epoch 16:
loss=0.005000825505703688 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 23.65it/s]

Test set: Average loss: 0.0196, Accuracy: 9943/10000 (99%)

Learning Rate = 0.001

## Epoch 17:
loss=0.0001455084275221452 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 23.96it/s]

Test set: Average loss: 0.0191, Accuracy: 9946/10000 (99%)

Learning Rate = 0.001

## Epoch 18:
loss=0.0022224395070225 batch_id=539: 100%|██████████| 540/540 [00:22<00:00, 23.51it/s]

Test set: Average loss: 0.0192, Accuracy: 9943/10000 (99%)

Learning Rate = 0.001